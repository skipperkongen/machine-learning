{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice's adventures in wonderla ...\n",
      "Total Characters:  144431\n",
      "Total distinct:  45\n",
      "Total Patterns:  144331\n",
      "Shape X: (144331, 100, 45)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create data + model\n",
    "\"\"\"\n",
    "\n",
    "with open('alice.txt') as fin:\n",
    "    raw_text = fin.read().lower()\n",
    "print (raw_text[0:30], '...')\n",
    "distinct_chars = sorted(list(set(raw_text)))\n",
    "n_chars = len(raw_text)\n",
    "n_distinct = len(distinct_chars)\n",
    "print (\"Total Characters: \", n_chars)\n",
    "print (\"Total distinct: \", n_distinct)\n",
    "\n",
    "int_to_char = dict([(i, c) for i, c in enumerate(distinct_chars)])\n",
    "char_to_oh = dict([(c, np.identity(n_distinct)[i: i+1][0]) for i, c in enumerate(distinct_chars)])\n",
    "\n",
    "window_size = 100\n",
    "data_X = []\n",
    "data_y = []\n",
    "for i in range(0, n_chars - window_size, 1): \n",
    "    seq_in = [char_to_oh[c] for c in raw_text[i: i + window_size]]\n",
    "    seq_out = char_to_oh[raw_text[i+window_size]]\n",
    "    data_X.append(seq_in)\n",
    "    data_y.append(seq_out)\n",
    "    \n",
    "n_patterns = len(data_X)\n",
    "print (\"Total Patterns: \", n_patterns)\n",
    "\n",
    "# Use one-hot encoded\n",
    "X = np.reshape(data_X, (n_patterns, window_size, n_distinct))\n",
    "y = np.reshape(data_y, (n_patterns, n_distinct))\n",
    "\n",
    "print('Shape X:', X.shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training\n",
    "\"\"\"\n",
    "\n",
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit(X, y, epochs=200, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Seed:\n",
      "\"  went on.\n",
      "\n",
      "'i do,' alice hastily replied; 'at least--at least i mean what i\n",
      "say--that's the same thi \"\n",
      "Generated text:\n",
      "ng, you know.'\n",
      "\n",
      "'not the same thing a bit!' said the hatter. 'you might just as well say\n",
      "that \"i see what i eat\" is the same thing as \"i get what i like\"!'\n",
      "\n",
      "'you might just as well say,' added the mock turtle a little anxiously.\n",
      "\n",
      "'yes,' said alice, 'we learned french and music.'\n",
      "\n",
      "'and washing?' said the mock turtle.\n",
      "\n",
      "'no, no! the adventures first,' said the gryphon in an impatient tone:\n",
      "'explanations take such a dreadful time.'\n",
      "\n",
      "so alice began thinking over other children she knew that were of the same age as herself, to\n",
      "see if she could have been changed for any of them.\n",
      "\n",
      "'i'm sure i'm not ada,' she said, 'for her hair goes in such long\n",
      "ringlets, and mine doesn't go in ringlets at all. and i don't think it's always getting up\n",
      "and walking off to other side. i wonder what they'll do next! and the other side of the\n",
      "door as it was in march.' as she said this, she looked up, and there was the cat\n",
      "again, sitting on a branch of a tree.\n",
      "\n",
      "'did you say pig, or fig?' said the cat.\n",
      "\n",
      "'i said pig,'\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Use model\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import random\n",
    "# load the network weights\n",
    "filename = \"weights-improvement-199-0.2582.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "def oh_to_char(oh):\n",
    "    return int_to_char[np.argmax(oh)]\n",
    "\n",
    "# pick a random seed\n",
    "\n",
    "pattern = [oh for oh in random.sample(data_X, 1)[0]]\n",
    "print ('---')\n",
    "print ('Seed:')\n",
    "print ('\"', ''.join([oh_to_char(oh) for oh in pattern]), '\"')\n",
    "\n",
    "print('Generated text:')\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    X_next = np.reshape(pattern, (1, window_size, n_distinct))\n",
    "    prediction = model.predict(X_next, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    predicted_char = int_to_char[index]\n",
    "    sys.stdout.write(predicted_char)\n",
    "    padding = char_to_oh[predicted_char]\n",
    "    pattern.append(padding)\n",
    "    pattern = pattern[1:]\n",
    "print ()\n",
    "print ('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice.ipynb                          requirements.txt\r\n",
      "README.md                            train-big.py\r\n",
      "alice.txt                            weights-improvement-199-0.2582.hdf5\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
